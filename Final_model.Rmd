---
title: "Model Building"
author: "Andy Liang"
date: "30/01/2022"
output: html_document
---

#Adding the holiday dates for the Nordic Countries
```{r}
holidays = read.csv("Holidays_Finland_Norway_Sweden_2015-2019.csv")

```

```{r}
holidays = holidays %>% select(Date,Country,Name) %>% mutate(Name = as.factor(Name), country = as.factor(Country), date = ymd(Date))
holidays = holidays[,c(3,4,5)]
```


#Added a feature that indicates if a certain date is a holiday
```{r}
#train set
train_final_fe = train_final %>% left_join(holidays,by = c("date","country"))
a_holiday = ifelse(is.na(train_final_fe$Name),0,1)
(train_final_fe = cbind(train_final_fe,a_holiday))

#test set
test_final_fe = test_final %>% left_join(holidays,by=c("date","country"))
a_holiday = ifelse(is.na(test_final_fe$Name),0,1)
(test_final_fe = cbind(test_final_fe,a_holiday))

```


```{r}
#columns to keep:date, country,store, product, numsold, weekend,gdp, and a_holiday

#round2,columns to keep: country,store,product,month,dat,weekend,year,gdp, a_holiday
#train set
train_set_finalized = train_final_fe[,c(3:8,10:12,14)]
train_set_finalized$country = as.factor(train_set_finalized$country)
#train_set_finalized$date = as.numeric(train_set_finalized$date)

#test set
test_set_finalized = test_final_fe[,c(3:7,9:11,13)]
test_set_finalized$country = as.factor(test_set_finalized$country)
#test_set_finalized$date = as.numeric(test_set_finalized$date)

```



```{r}
head(train_set_finalized)

head(test_set_finalized)

```


```{r}
correlation_plot = model.matrix(~0+.,data = train_set_finalized) %>% cor() %>% corrplot(method = "number",tl.cex = 0.75)

correlation_plot
```



#Removing higly correlated features, normal scale
```{r}
#get column index of the highly correlated features; chosen cutoff is 0.8
cutoff=findCorrelation(cor(model.matrix(~0+.,data = train_set_finalized[,-8])),cutoff = 0.9,verbose=TRUE)

#all features are less than the cutoff so i don't remove any features.

#One Hot Encoding
dummy = dummyVars("~.",data=train_set_finalized)
training_data = data.frame(predict(dummy,newdata=train_set_finalized))
dummy = dummyVars("~.",data=test_set_finalized)
testing_data = data.frame(predict(dummy,newdata=test_set_finalized))


#Standardizing the data
#variables that need to be standardized: month,day,weekend,year,gdp
train_set_finalized = as.data.frame(scale(training_data[,-9],center=TRUE,scale = TRUE))
train_set_finalized = cbind(train_set_finalized,training_data[,9])
colnames(train_set_finalized)[15] = "num_sold"
test_set_finalized = as.data.frame(scale(testing_data[,-12],center=TRUE,scale = TRUE))

```



#Splititng a partition of the train set for a validation set 
```{r}
#random forest 

set.seed(4198)
split = createDataPartition(train_set_finalized$num_sold, times = 1,list = FALSE,p = 0.75)

#train set
t_set = train_set_finalized[split,]

#valid set
v_set = train_set_finalized[-split,]
```


#rf tune
```{r}

rfGrid = expand.grid(mtry=c(3,4,5,6,7))

trainctrl = trainControl(method = "cv",number = 5)

rf_tune_fit = train(num_sold ~ .,
data = t_set,
"rf",
trControl = trainctrl,tuneGrid = rfGrid,verbose=FALSE)

preds=predict(rf_tune_fit,newdata = v_set)

(rmse=mean((v_set$num_sold-preds)^2))
```


#xgb tune
```{r}
xgb_grid = expand.grid(nrounds = c(500),max_depth = c(2,4,6,8,10),
eta = c(0.01,0.05,0.1,0.3),
gamma = c(1,2),
colsample_bytree=c(0.5,1),
min_child_weight=1,
subsample=c(1)
)

trainctrl = trainControl(method="cv", number = 5, allowParallel = TRUE)

xgb_tune_fit = train(num_sold~.,data=t_set,
method="xgbTree",
trControl=trainctrl,
tuneGrid=xgb_grid,
verbose=FALSE)
```


```{r}

preds=predict(xgb_tune_fit,newdata = v_set)

(rmse=mean((v_set$num_sold-preds)^2))

```

#xgboost model
```{r}
xgb_grid = expand.grid(nrounds = c(500),max_depth = c(2,4,6,8,10,13),
eta = c(0.01,0.05,0.1,0.3,0.5),
gamma = c(1,2),
colsample_bytree=c(0.5,1),
min_child_weight=1,
subsample=c(1)
)

trainctrl = trainControl(method="cv", number = 5, allowParallel = TRUE)

xgb_tune_fit = train(num_sold~.,data=train_set_finalized,
method="xgbTree",
trControl=trainctrl,
tuneGrid=xgb_grid,
verbose=FALSE)


xgb_tune_fit$bestTune
```



#prediction and submission
```{r}
preds2 = predict(xgb_tune_fit,test_set_finalized)

submission$num_sold = preds2

write.table(submission,"kaggle_JanTPS2.csv",row.names = FALSE,sep=",")

```
